"""
WhisperX éŸ³é »è½‰ç²¾æº–å°é½Šå­—å¹•å·¥å…· (Google Colab ç‰ˆ)
=====================================================

é€™æ˜¯ä¸€å€‹åœ¨ Google Colab ç’°å¢ƒä¸­é‹è¡Œçš„äº’å‹•å¼å·¥å…·ï¼Œåˆ©ç”¨ WhisperX å¯¦ç¾é«˜ç²¾åº¦çš„èªéŸ³è­˜åˆ¥èˆ‡é€å­—å°é½Šï¼Œ
ä¸¦è‡ªå‹•ç”Ÿæˆå¤šç¨®æ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼ˆSRTã€VTTã€TSVã€TXTï¼‰ã€‚è©²å·¥å…·ç‰¹åˆ¥é©ç”¨æ–¼éœ€è¦ç²¾ç¢ºæ™‚é–“æˆ³çš„å ´åˆï¼Œ
å¦‚å­—å¹•è£½ä½œã€èªè¨€å­¸ç¿’ã€è¦–é »å¾ŒæœŸç­‰ã€‚

åŠŸèƒ½ç‰¹é»
--------
- **ç²¾æº–äººè²æª¢æ¸¬**ï¼šåŸºæ–¼ FFmpeg çš„éœéŸ³æª¢æ¸¬æŠ€è¡“ï¼Œè‡ªå‹•æå–éŸ³é »ä¸­çš„äººè²ç‰‡æ®µï¼ˆæ¯«ç§’ç´šï¼‰ã€‚
- **é€å­—å°é½Šå­—å¹•**ï¼šä½¿ç”¨ WhisperX é€²è¡ŒèªéŸ³è­˜åˆ¥ï¼Œä¸¦å°æ¯å€‹å­—/è©é€²è¡Œç²¾ç¢ºçš„æ™‚é–“å°é½Šã€‚
- **å¤šæ ¼å¼è¼¸å‡º**ï¼šè‡ªå‹•ç”Ÿæˆ SRTã€VTTã€TSVã€TXT å››ç¨®å¸¸è¦‹å­—å¹•æ ¼å¼ï¼Œæ»¿è¶³ä¸åŒå¹³è‡ºéœ€æ±‚ã€‚
- **æç¤ºè©è¨˜æ†¶**ï¼šæ”¯æ´å¸¸ç”¨æç¤ºè©ï¼ˆInitial Promptï¼‰çš„ä¿å­˜èˆ‡è¼‰å…¥ï¼Œæé«˜ç‰¹å®šå ´æ™¯çš„è­˜åˆ¥æº–ç¢ºç‡ã€‚
- **éˆæ´»çš„æ–‡ä»¶ä¾†æº**ï¼šå¯ç›´æ¥è®€å– Google Drive ä¸­çš„éŸ³é »æ–‡ä»¶ï¼Œæˆ–æ‰‹å‹•ä¸Šå‚³æœ¬åœ°æ–‡ä»¶ã€‚
- **å¤šèªè¨€æ”¯æ´**ï¼šæ”¯æ´ç¹é«”ä¸­æ–‡ã€ç°¡é«”ä¸­æ–‡ã€ç¾å¼è‹±èªã€è‹±å¼è‹±èªã€æ—¥èªã€éŸ“èªã€æ³•èªã€å¾·èªã€è¥¿ç­ç‰™èªç­‰ï¼Œä¸¦è‡ªå‹•ä½¿ç”¨å°æ‡‰çš„æª”æ¡ˆå¾Œç¶´ã€‚
- **æ¨¡å‹é¸æ“‡**ï¼šå¯æ ¹æ“š GPU è¨˜æ†¶é«”é¸æ“‡ Whisper æ¨¡å‹å¤§å°ï¼ˆtiny/base/small/medium/largeï¼‰ã€‚

ä¾è³´ç’°å¢ƒ
--------
- Python 3.8+
- FFmpeg
- whisperx
- torch
- soundfile
- numpy
- ipywidgets (Colab äº¤äº’)
- google.colab (ç‰¹å®šç’°å¢ƒ)

ä½¿ç”¨æ–¹æ³•æ¦‚è¿°
------------
1. åœ¨ Google Colab ä¸­åŸ·è¡Œæ­¤è…³æœ¬ï¼Œå®ƒæœƒè‡ªå‹•å®‰è£æ‰€éœ€ä¾è³´ã€‚
2. é¸æ“‡éŸ³é »æ–‡ä»¶ä¾†æºï¼ˆGoogle Drive æˆ–æ‰‹å‹•ä¸Šå‚³ï¼‰ã€‚
3. è¨­å®šå­—å¹•èªè¨€ã€åˆå§‹æç¤ºè©å’Œ Whisper æ¨¡å‹å¤§å°ã€‚
4. é»æ“Šã€Œé–‹å§‹ç”Ÿæˆå­—å¹•ã€æŒ‰éˆ•ï¼Œå·¥å…·å°‡è‡ªå‹•å®Œæˆäººè²æå–ã€èªéŸ³è­˜åˆ¥ã€é€å­—å°é½Šèˆ‡å­—å¹•è¼¸å‡ºã€‚
5. è¼¸å‡ºæ–‡ä»¶æœƒæ‰“åŒ…ç‚º ZIP å£“ç¸®åŒ…ï¼Œå¯ä¸‹è¼‰åˆ°æœ¬åœ°æˆ–ä¿å­˜è‡³ Google Driveã€‚

å‡½æ•¸ç°¡ä»‹
--------
- `load_saved_prompts()`: å¾æœ¬åœ° JSON æ–‡ä»¶è¼‰å…¥å·²ä¿å­˜çš„æç¤ºè©åˆ—è¡¨ã€‚
- `save_prompt(prompt)`: å°‡æ–°çš„æç¤ºè©æ·»åŠ åˆ°ä¿å­˜åˆ—è¡¨ä¸¦æŒä¹…åŒ–ã€‚
- `extract_voice_segments(audio_path, output_json, min_volume, min_duration)`:
  ä½¿ç”¨ FFmpeg åˆ†æéŸ³é »ï¼Œæå–äººè²æ™‚é–“æ®µï¼ˆæ¯«ç§’ç´šï¼‰ï¼Œçµæœä¿å­˜ç‚º JSONã€‚
- `format_time_srt(seconds)`: å°‡ç§’æ•¸è½‰æ›ç‚º SRT å­—å¹•çš„æ™‚é–“æ ¼å¼ (HH:MM:SS,mmm)ã€‚
- `format_time_vtt(seconds)`: å°‡ç§’æ•¸è½‰æ›ç‚º VTT å­—å¹•çš„æ™‚é–“æ ¼å¼ (HH:MM:SS.mmm)ã€‚
- `save_subtitle_formats(all_subtitles, base_filename, lang_suffix)`:
  æ ¹æ“šå°é½Šçµæœç”Ÿæˆ SRTã€VTTã€TSVã€TXT å››ç¨®æ ¼å¼çš„å­—å¹•æ–‡ä»¶ï¼Œè¿”å›æ–‡ä»¶è·¯å¾‘åˆ—è¡¨ã€‚
- `transcribe_with_whisperx(audio_path, voice_segments, base_filename, lang, initial_prompt, model_size)`:
  å°æ¯å€‹é å…ˆæå–çš„äººè²ç‰‡æ®µé€²è¡Œ WhisperX è­˜åˆ¥èˆ‡å°é½Šï¼Œè¿”å›æ‰€æœ‰å­—å¹•ç‰‡æ®µçš„è©³ç´°è³‡æ–™ã€‚
- `main_interface()`: æ§‹å»º Colab äº¤äº’å¼ç•Œé¢ï¼Œè™•ç†ç”¨æˆ¶è¼¸å…¥ä¸¦å”èª¿æ•´å€‹è™•ç†æµç¨‹ã€‚
- `install_dependencies()`: å®‰è£ FFmpeg åŠå¿…è¦çš„ Python å¥—ä»¶ã€‚

ç‰ˆæœ¬æ­·å²
--------
- **v0.1.0.1** (2025-02-22): åˆå§‹ç‰ˆæœ¬ï¼Œå¯¦ç¾åŸºæœ¬åŠŸèƒ½ã€‚
- **v0.1.0.2** (2025-02-23): æ–°å¢èªè¨€åœ°å€é¸æ“‡ï¼Œå­—å¹•æª”æ¡ˆå¾Œç¶´è‡ªå‹•å°æ‡‰ï¼ˆå¦‚ zh-TW, zh-CN, en-US ç­‰ï¼‰ã€‚
"""

import os
import json
import subprocess
import whisperx
import torch
import shutil
import zipfile
from pathlib import Path
from google.colab import drive, files
import ipywidgets as widgets
from IPython.display import display, clear_output, HTML

# ===================== åˆå§‹åŒ–é…ç½® =====================
# åŠ è¼‰å·²ä¿å­˜çš„promptï¼ˆå¦‚æœå­˜åœ¨ï¼‰
PROMPT_SAVE_PATH = "saved_prompts.json"
def load_saved_prompts():
    """åŠ è¼‰ä¿å­˜çš„æç¤ºè©åˆ—è¡¨"""
    if os.path.exists(PROMPT_SAVE_PATH):
        with open(PROMPT_SAVE_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    return ["è«‹èªªæ™®é€šè©±", "Speak clearly", "ã¯ã£ãã‚Šè©±ã—ã¦ãã ã•ã„"]

def save_prompt(prompt):
    """ä¿å­˜æ–°çš„æç¤ºè©åˆ°åˆ—è¡¨"""
    prompts = load_saved_prompts()
    if prompt not in prompts:
        prompts.append(prompt)
        with open(PROMPT_SAVE_PATH, "w", encoding="utf-8") as f:
            json.dump(prompts, f, ensure_ascii=False, indent=2)
    return prompts

# ===================== æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ =====================
def extract_voice_segments(audio_path, output_json="voice_segments.json", min_volume=-30, min_duration=0.5):
    """ä½¿ç”¨FFmpegæå–éŸ³é »ä¸­çš„äººè²æ™‚é–“æ®µï¼ˆæ¯«ç§’ç´šï¼‰"""
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"éŸ³é »æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

    # FFmpegå‘½ä»¤ï¼šåˆ†æéŸ³é »éŸ³é‡ï¼Œè¼¸å‡ºéœéŸ³/ééœéŸ³æ™‚é–“æ®µ
    cmd = [
        "ffmpeg",
        "-i", audio_path,
        "-af", f"silencedetect=noise={min_volume}dB:d={min_duration}",
        "-f", "null",
        "-"
    ]

    # åŸ·è¡ŒFFmpegå‘½ä»¤ä¸¦æ•ç²è¼¸å‡º
    result = subprocess.run(cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, text=True)
    output = result.stderr

    # è§£æFFmpegè¼¸å‡ºï¼Œæå–äººè²æ™‚é–“æ®µ
    voice_segments = []
    silence_start = None

    for line in output.split("\n"):
        # æª¢æ¸¬éœéŸ³é–‹å§‹ï¼ˆæ„å‘³ç€äººè²çµæŸï¼‰
        if "silence_start:" in line:
            try:
                # æå–éœéŸ³é–‹å§‹æ™‚é–“ï¼ˆç§’ï¼‰
                start_time = float(line.split("silence_start: ")[1].strip())
                if silence_start is not None:
                    # è¨ˆç®—äººè²ç‰‡æ®µï¼šä¸Šä¸€å€‹éœéŸ³çµæŸ åˆ° ç•¶å‰éœéŸ³é–‹å§‹
                    voice_start = int(silence_start * 1000)  # è½‰æ¯«ç§’
                    voice_end = int(start_time * 1000)
                    # éæ¿¾éçŸ­çš„ç‰‡æ®µ
                    if (voice_end - voice_start) > (min_duration * 1000):
                        voice_segments.append({"start": voice_start, "end": voice_end})
            except:
                continue

        # æª¢æ¸¬éœéŸ³çµæŸï¼ˆæ„å‘³ç€äººè²é–‹å§‹ï¼‰
        elif "silence_end:" in line:
            try:
                # æå–éœéŸ³çµæŸæ™‚é–“ï¼ˆç§’ï¼‰
                silence_start = float(line.split("silence_end: ")[1].split(" |")[0].strip())
            except:
                continue

    # è™•ç†éŸ³é »æœ«å°¾çš„äººè²ç‰‡æ®µï¼ˆå¦‚æœæœ€å¾Œä¸æ˜¯éœéŸ³çµæŸï¼‰
    duration_cmd = [
        "ffmpeg",
        "-i", audio_path,
        "-f", "null",
        "-"
    ]
    duration_result = subprocess.run(duration_cmd, stderr=subprocess.PIPE, stdout=subprocess.PIPE, text=True)
    for line in duration_result.stderr.split("\n"):
        if "Duration:" in line:
            try:
                duration_str = line.split("Duration: ")[1].split(",")[0].strip()
                h, m, s = duration_str.split(":")
                total_seconds = int(h) * 3600 + int(m) * 60 + float(s)
                total_ms = int(total_seconds * 1000)
                # å¦‚æœæœ€å¾Œæœ‰æœªçµæŸçš„äººè²ç‰‡æ®µ
                if silence_start is not None:
                    voice_start = int(silence_start * 1000)
                    voice_end = total_ms
                    if (voice_end - voice_start) > (min_duration * 1000):
                        voice_segments.append({"start": voice_start, "end": voice_end})
            except:
                continue

    # ä¿å­˜äººè²ç‰‡æ®µåˆ°JSON
    with open(output_json, "w", encoding="utf-8") as f:
        json.dump(voice_segments, f, ensure_ascii=False, indent=2)

    print(f"âœ… æå–åˆ° {len(voice_segments)} å€‹äººè²ç‰‡æ®µï¼Œå·²ä¿å­˜åˆ° {output_json}")
    return voice_segments

def format_time_srt(seconds):
    """è½‰æ›æ™‚é–“çˆ²SRTæ ¼å¼ (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{ms:03d}"

def format_time_vtt(seconds):
    """è½‰æ›æ™‚é–“çˆ²VTTæ ¼å¼ (HH:MM:SS.mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    ms = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d}.{ms:03d}"

def save_subtitle_formats(all_subtitles, base_filename, lang_suffix):
    """ä¿å­˜å¤šç¨®æ ¼å¼çš„å­—å¹•æ–‡ä»¶"""
    # ç”Ÿæˆå¸¶èªè¨€å¾Œç¶´çš„åŸºç¤æ–‡ä»¶å
    file_base = f"{base_filename}.{lang_suffix}"

    # 1. SRTæ ¼å¼
    srt_file = f"{file_base}.srt"
    with open(srt_file, "w", encoding="utf-8") as f:
        for sub in all_subtitles:
            f.write(f"{sub['id']}\n")
            f.write(f"{sub['start_srt']} --> {sub['end_srt']}\n")
            f.write(f"{sub['text']}\n\n")

    # 2. VTTæ ¼å¼
    vtt_file = f"{file_base}.vtt"
    with open(vtt_file, "w", encoding="utf-8") as f:
        f.write("WEBVTT\n\n")
        for sub in all_subtitles:
            f.write(f"{sub['start_vtt']} --> {sub['end_vtt']}\n")
            f.write(f"{sub['text']}\n\n")

    # 3. TSVæ ¼å¼
    tsv_file = f"{file_base}.tsv"
    with open(tsv_file, "w", encoding="utf-8") as f:
        f.write("ID\tStart(ms)\tEnd(ms)\tStart\tEnd\tText\n")
        for sub in all_subtitles:
            start_ms = int(sub['start_sec'] * 1000)
            end_ms = int(sub['end_sec'] * 1000)
            f.write(f"{sub['id']}\t{start_ms}\t{end_ms}\t{sub['start_srt']}\t{sub['end_srt']}\t{sub['text']}\n")

    # 4. TXTæ ¼å¼ï¼ˆç´”æ–‡æœ¬ï¼‰
    txt_file = f"{file_base}.txt"
    with open(txt_file, "w", encoding="utf-8") as f:
        full_text = "".join([sub['text'] for sub in all_subtitles])
        f.write(full_text)

    return [srt_file, vtt_file, tsv_file, txt_file]

def transcribe_with_whisperx(audio_path, voice_segments, base_filename, lang="zh", initial_prompt="", model_size="base"):
    """ä½¿ç”¨WhisperXå°äººè²ç‰‡æ®µé€²è¡Œé€å­—ç²¾æº–å°é½Šï¼Œç”Ÿæˆå¤šæ ¼å¼å­—å¹•"""
    # è¨­ç½®è¨­å‚™ï¼ˆè‡ªå‹•æª¢æ¸¬GPU/CPUï¼‰
    device = "cuda" if torch.cuda.is_available() else "cpu"
    batch_size = 16 if torch.cuda.is_available() else 4
    compute_type = "float16" if torch.cuda.is_available() else "int8"

    print(f"âš™ï¸ ä½¿ç”¨è¨­å‚™: {device}")
    print(f"âš™ï¸ æ¨¡å‹å¤§å°: {model_size}, èªè¨€: {lang}")
    print(f"âš™ï¸ åˆå§‹æç¤ºè©: {initial_prompt}")

    # 1. åŠ è¼‰WhisperXæ¨¡å‹
    model = whisperx.load_model(
        model_size,
        device,
        compute_type=compute_type,
        language=lang
    )

    # 2. åŠ è¼‰å°é½Šæ¨¡å‹
    model_a, metadata = whisperx.load_align_model(language_code=lang, device=device)

    # å­˜å„²æ‰€æœ‰å­—å¹•ç‰‡æ®µ
    all_subtitles = []
    segment_id = 1

    # 3. é€å€‹è™•ç†äººè²ç‰‡æ®µ
    for seg in voice_segments:
        start_ms = seg["start"]
        end_ms = seg["end"]
        start_sec = start_ms / 1000
        end_sec = end_ms / 1000
        duration_sec = end_sec - start_sec

        print(f"\nğŸ”¤ è™•ç†ç‰‡æ®µ {segment_id}: {start_ms}ms - {end_ms}ms (æ™‚é•·: {duration_sec:.2f}ç§’)")

        # è‡¨æ™‚åˆ‡å‰²éŸ³é »ç‰‡æ®µ
        temp_audio = f"temp_segment_{segment_id}.wav"
        try:
            # ä½¿ç”¨FFmpegåˆ‡å‰²éŸ³é »ç‰‡æ®µ
            subprocess.run([
                "ffmpeg",
                "-ss", str(start_sec),
                "-to", str(end_sec),
                "-i", audio_path,
                "-vn", "-acodec", "pcm_s16le",
                "-y", temp_audio
            ], check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)

            # 4. è­˜åˆ¥éŸ³é »ç‰‡æ®µï¼ˆå¸¶åˆå§‹æç¤ºè©ï¼‰
            audio = whisperx.load_audio(temp_audio)
            result = model.transcribe(
                audio,
                batch_size=batch_size,
                initial_prompt=initial_prompt
            )

            # 5. ç²¾æº–å°é½Šï¼ˆé€å­—ç´šåˆ¥ï¼‰
            result_aligned = whisperx.align(
                result["segments"],
                model_a,
                metadata,
                audio,
                device,
                return_char_alignments=True
            )

            # 6. è™•ç†å°é½Šçµæœ
            for word_seg in result_aligned["segments"]:
                for char in word_seg["char_alignments"]:
                    # è¨ˆç®—å­—ç¬¦çš„çµ•å°æ™‚é–“ï¼ˆåŠ ä¸Šç‰‡æ®µèµ·å§‹æ™‚é–“ï¼‰
                    char_start = start_sec + char["start"]
                    char_end = start_sec + char["end"]
                    char_text = char["char"]

                    # éæ¿¾ç©ºå­—ç¬¦
                    if char_text.strip() == "":
                        continue

                    # è½‰æ›å¤šç¨®æ™‚é–“æ ¼å¼
                    start_srt = format_time_srt(char_start)
                    end_srt = format_time_srt(char_end)
                    start_vtt = format_time_vtt(char_start)
                    end_vtt = format_time_vtt(char_end)

                    # æ·»åŠ åˆ°å­—å¹•åˆ—è¡¨
                    all_subtitles.append({
                        "id": len(all_subtitles) + 1,
                        "start_sec": char_start,
                        "end_sec": char_end,
                        "start_srt": start_srt,
                        "end_srt": end_srt,
                        "start_vtt": start_vtt,
                        "end_vtt": end_vtt,
                        "text": char_text
                    })

        except Exception as e:
            print(f"âŒ è™•ç†ç‰‡æ®µ {segment_id} å‡ºéŒ¯: {e}")
        finally:
            # åˆªé™¤è‡¨æ™‚éŸ³é »æ–‡ä»¶
            if os.path.exists(temp_audio):
                os.remove(temp_audio)

        segment_id += 1

    return all_subtitles

# ===================== Colabäº¤äº’ç•Œé¢ =====================
def main_interface():
    clear_output()
    print("ğŸ“Œ éŸ³é »è½‰ç²¾æº–å°é½Šå­—å¹•å·¥å…· (Google Colab ç‰ˆ)")
    print("="*50)

    # 1. æ›è¼‰Google Drive
    drive_mounted = False
    drive_path = "/content/drive/MyDrive/Conv2Sub"
    output_drive_path = f"{drive_path}/subtitle_output"

    try:
        drive.mount('/content/drive')
        drive_mounted = True
        print("âœ… å·²æˆåŠŸæ›è¼‰Googleé›²ç«¯ç¡¬ç›¤")

        # å‰µå»ºç›®éŒ„
        os.makedirs(drive_path, exist_ok=True)
        os.makedirs(output_drive_path, exist_ok=True)
        print(f"ğŸ“‚ é›²ç«¯ç¡¬ç›¤å·¥ä½œç›®éŒ„: {drive_path}")

        # åˆ—å‡ºConv2Subç›®éŒ„ä¸‹çš„éŸ³é »æ–‡ä»¶
        audio_extensions = ['.mp3', '.wav', '.m4a', '.flac', '.ogg', '.wma']
        drive_audio_files = []
        for file in os.listdir(drive_path):
            if any(file.lower().endswith(ext) for ext in audio_extensions):
                drive_audio_files.append(file)

    except Exception as e:
        print(f"âš ï¸ æ›è¼‰é›²ç«¯ç¡¬ç›¤å¤±æ•—: {e}")
        drive_audio_files = []

    # 2. éŸ³é »æ–‡ä»¶é¸æ“‡
    print("\nğŸ“ éŸ³é »æ–‡ä»¶ä¾†æºé¸æ“‡:")
    if drive_audio_files:
        audio_source_options = ["ğŸ“‚ é›²ç«¯ç¡¬ç›¤æ–‡ä»¶"] + drive_audio_files + ["ğŸ“¤ æ‰‹å‹•ä¸Šå‚³æ–‡ä»¶"]
    else:
        audio_source_options = ["ğŸ“‚ é›²ç«¯ç¡¬ç›¤æ–‡ä»¶ï¼ˆæœªæª¢æ¸¬åˆ°ï¼‰", "ğŸ“¤ æ‰‹å‹•ä¸Šå‚³æ–‡ä»¶"]

    audio_source = widgets.Dropdown(
        options=audio_source_options,
        value=audio_source_options[0],
        description='é¸æ“‡:',
        style={'description_width': 'initial'}
    )
    display(audio_source)

    # 3. èªè¨€é¸æ“‡ï¼ˆæ“´å……åœ°å€å¾Œç¶´ï¼‰
    print("\nğŸŒ å­—å¹•èªè¨€é¸æ“‡:")
    # èªè¨€æ˜ å°„ï¼šé¡¯ç¤ºåç¨± -> (whisperèªè¨€ä»£ç¢¼, æª”æ¡ˆå¾Œç¶´)
    lang_mapping = {
        "ç¹é«”ä¸­æ–‡": {"code": "zh", "suffix": "zh-TW"},
        "ç°¡é«”ä¸­æ–‡": {"code": "zh", "suffix": "zh-CN"},
        "è‹±æ–‡ (ç¾åœ‹)": {"code": "en", "suffix": "en-US"},
        "è‹±æ–‡ (è‹±åœ‹)": {"code": "en", "suffix": "en-GB"},
        "æ—¥æ–‡": {"code": "ja", "suffix": "ja"},
        "éŸ“æ–‡": {"code": "ko", "suffix": "ko"},
        "æ³•èª": {"code": "fr", "suffix": "fr"},
        "å¾·èª": {"code": "de", "suffix": "de"},
        "è¥¿ç­ç‰™èª": {"code": "es", "suffix": "es"},
        # å¯æ ¹æ“šéœ€æ±‚ç¹¼çºŒæ·»åŠ 
    }
    lang_selector = widgets.Dropdown(
        options=list(lang_mapping.keys()),
        value="ç¹é«”ä¸­æ–‡",
        description='èªè¨€:',
        style={'description_width': 'initial'}
    )
    display(lang_selector)

    # 4. Initial Prompté¸æ“‡
    print("\nğŸ’¡ åˆå§‹æç¤ºè© (Initial Prompt):")
    saved_prompts = load_saved_prompts()
    prompt_options = saved_prompts + ["[æ–°å¢] è‡ªå®šç¾©æç¤ºè©"]
    prompt_selector = widgets.Dropdown(
        options=prompt_options,
        value=prompt_options[0],
        description='æç¤ºè©:',
        style={'description_width': 'initial'}
    )
    custom_prompt = widgets.Text(
        value="",
        placeholder="è¼¸å…¥è‡ªå®šç¾©æç¤ºè©...",
        description='è‡ªå®šç¾©:',
        style={'description_width': 'initial'},
        disabled=True
    )

    # æç¤ºè©é¸æ“‡è¯å‹•
    def on_prompt_change(change):
        if change['new'] == "[æ–°å¢] è‡ªå®šç¾©æç¤ºè©":
            custom_prompt.disabled = False
        else:
            custom_prompt.disabled = True
            custom_prompt.value = ""

    prompt_selector.observe(on_prompt_change, names='value')
    display(prompt_selector)
    display(custom_prompt)

    # 5. æ¨¡å‹å¤§å°é¸æ“‡ (æ•´åˆ WhisperX æœ€æ–°æ”¯æ´æ¨¡å‹)
    print("\nâš™ï¸ æ¨¡å‹å¤§å°é¸æ“‡ (å»ºè­°æ ¹æ“šæ‚¨çš„ GPU é¡¯å­˜é¸æ“‡):")
    model_options = {
        "Tiny (æœ€å¿«ï¼Œç²¾åº¦ä½ï¼Œéœ€ ~1GB VRAM)": "tiny",
        "Base (å¹³è¡¡ï¼Œéœ€ ~1GB VRAM)": "base",
        "Small (è¼ƒç²¾æº–ï¼Œéœ€ ~2GB VRAM)": "small",
        "Medium (é«˜ç²¾æº–ï¼Œéœ€ ~5GB VRAM)": "medium",
        "Large-v3-Turbo (æ¥µé€Ÿæ¨è–¦ï¼ç²¾åº¦æ¥è¿‘ Large ä½†å¿« 6 å€ï¼Œéœ€ ~6GB VRAM)": "large-v3-turbo",
        "Large-v2 (å‚³çµ±æœ€ç²¾æº–æ¨™ç«¿ï¼Œéœ€ ~10GB VRAM)": "large-v2",
        "Large-v3 (ç›®å‰å¤šèªç³»æœ€å¼·ï¼Œéœ€ ~10GB VRAM)": "large-v3"
    }

    model_selector = widgets.Dropdown(
        options=list(model_options.keys()),
        value="Large-v3-Turbo (æ¥µé€Ÿæ¨è–¦ï¼ç²¾åº¦æ¥è¿‘ Large ä½†å¿« 6 å€ï¼Œéœ€ ~6GB VRAM)", # é è¨­æ¨è–¦ Turbo ç‰ˆ
        description='é¸æ“‡æ¨¡å‹:',
        style={'description_width': 'initial'},
        layout={'width': 'max-content'} # è‡ªå‹•èª¿æ•´å¯¬åº¦ä»¥é¡¯ç¤ºå®Œæ•´æ–‡å­—
    )

    display(model_selector)

    # 6. åŸ·è¡ŒæŒ‰éˆ•
    print("\nğŸš€ é–‹å§‹è½‰æ›:")
    run_button = widgets.Button(
        description="é–‹å§‹ç”Ÿæˆå­—å¹•",
        button_style='success',
        icon='play'
    )
    display(run_button)

    # ===================== åŸ·è¡Œé‚è¼¯ =====================
    def on_run_click(b):
        clear_output(wait=True)
        print("ğŸš€ é–‹å§‹è™•ç†...")

        # ç²å–é¸æ“‡çš„åƒæ•¸
        selected_audio = audio_source.value
        selected_display = lang_selector.value
        lang_info = lang_mapping[selected_display]
        selected_lang_code = lang_info["code"]   # å‚³çµ¦ WhisperX çš„èªè¨€åƒæ•¸ï¼ˆåŸºç¤ä»£ç¢¼ï¼‰
        lang_suffix = lang_info["suffix"]        # ç”¨æ–¼æª”æ¡ˆåç¨±çš„å¾Œç¶´
        selected_model = model_options[model_selector.value]

        # è™•ç†æç¤ºè©
        if prompt_selector.value == "[æ–°å¢] è‡ªå®šç¾©æç¤ºè©" and custom_prompt.value.strip():
            selected_prompt = custom_prompt.value.strip()
            save_prompt(selected_prompt)
            print(f"ğŸ’¡ ä½¿ç”¨è‡ªå®šç¾©æç¤ºè©ä¸¦ä¿å­˜: {selected_prompt}")
        else:
            selected_prompt = prompt_selector.value

        # è™•ç†éŸ³é »æ–‡ä»¶
        audio_file_path = ""
        is_drive_file = False

        if selected_audio.startswith("ğŸ“¤"):
            # æ‰‹å‹•ä¸Šå‚³æ–‡ä»¶
            print("\nğŸ“¤ è«‹ä¸Šå‚³éŸ³é »æ–‡ä»¶...")
            uploaded = files.upload()
            if uploaded:
                audio_filename = list(uploaded.keys())[0]
                audio_file_path = f"/content/{audio_filename}"
                temp_dir = f"/content/temp_subtitles"
                os.makedirs(temp_dir, exist_ok=True)
                print(f"âœ… å·²ä¸Šå‚³æ–‡ä»¶: {audio_filename}")
        elif selected_audio in drive_audio_files:
            # é›²ç«¯ç¡¬ç›¤æ–‡ä»¶
            audio_file_path = f"{drive_path}/{selected_audio}"
            is_drive_file = True
            print(f"âœ… é¸æ“‡é›²ç«¯ç¡¬ç›¤æ–‡ä»¶: {audio_file_path}")
        else:
            print("âŒ æœªé¸æ“‡æœ‰æ•ˆçš„éŸ³é »æ–‡ä»¶ï¼")
            return

        # æå–æ–‡ä»¶åï¼ˆä¸å«æ“´å±•åï¼‰
        audio_basename = os.path.splitext(os.path.basename(audio_file_path))[0]

        try:
            # æ­¥é©Ÿ1ï¼šæå–äººè²ç‰‡æ®µ
            print("\nğŸ” æ­£åœ¨åˆ†æéŸ³é »ï¼Œæå–äººè²ç‰‡æ®µ...")
            segments_json = f"{audio_basename}.voice_segments.{lang_suffix}.json"
            voice_segments = extract_voice_segments(audio_file_path, segments_json)

            if not voice_segments:
                print("âŒ æœªæª¢æ¸¬åˆ°äººè²ç‰‡æ®µï¼")
                return

            # æ­¥é©Ÿ2ï¼šWhisperXé€å­—å°é½Š
            print("\nğŸ™ï¸ æ­£åœ¨é€²è¡ŒèªéŸ³è­˜åˆ¥å’Œé€å­—å°é½Š...")
            all_subtitles = transcribe_with_whisperx(
                audio_file_path,
                voice_segments,
                audio_basename,
                lang=selected_lang_code,          # å‚³éåŸºç¤èªè¨€ä»£ç¢¼
                initial_prompt=selected_prompt,
                model_size=selected_model
            )

            # æ­¥é©Ÿ3ï¼šä¿å­˜å¤šç¨®æ ¼å¼å­—å¹•ï¼ˆä½¿ç”¨åœ°å€å¾Œç¶´ï¼‰
            print("\nğŸ’¾ æ­£åœ¨ä¿å­˜å­—å¹•æ–‡ä»¶...")
            subtitle_files = save_subtitle_formats(all_subtitles, audio_basename, lang_suffix)
            subtitle_files.append(segments_json)  # åŠ å…¥äººè²ç‰‡æ®µJSON

            # æ­¥é©Ÿ4ï¼šè™•ç†è¼¸å‡ºæ–‡ä»¶
            if is_drive_file:
                # é›²ç«¯ç¡¬ç›¤æ–‡ä»¶ï¼šæ‰“åŒ…ä¿å­˜åˆ°subtitle_output
                zip_filename = f"{audio_basename}.subtitles.{lang_suffix}.zip"
                zip_path = f"{output_drive_path}/{zip_filename}"

                # æ‰“åŒ…æ–‡ä»¶
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file in subtitle_files:
                        if os.path.exists(file):
                            zipf.write(file, os.path.basename(file))

                # æ¸…ç†è‡¨æ™‚æ–‡ä»¶
                for file in subtitle_files:
                    if os.path.exists(file):
                        os.remove(file)

                print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
                print(f"ğŸ“¦ å­—å¹•æ–‡ä»¶å·²æ‰“åŒ…ä¿å­˜åˆ°é›²ç«¯ç¡¬ç›¤:")
                print(f"   {zip_path}")
                print(f"\nğŸ’¡ ä½ å¯ä»¥åœ¨Googleé›²ç«¯ç¡¬ç›¤çš„ Conv2Sub/subtitle_output ç›®éŒ„æ‰¾åˆ°è©²æ–‡ä»¶")

            else:
                # æ‰‹å‹•ä¸Šå‚³æ–‡ä»¶ï¼šä¿å­˜åˆ°è‡¨æ™‚ç›®éŒ„ä¸¦æç¤ºä¸‹è¼‰
                for file in subtitle_files:
                    if os.path.exists(file):
                        shutil.move(file, temp_dir)

                print(f"\nğŸ‰ è™•ç†å®Œæˆï¼")
                print(f"ğŸ“‚ å­—å¹•æ–‡ä»¶å·²ä¿å­˜åˆ°è‡¨æ™‚ç›®éŒ„: {temp_dir}")
                print(f"\nâš ï¸  é‡è¦æç¤ºï¼š")
                print(f"   - Colabè‡¨æ™‚æ–‡ä»¶æœƒåœ¨æœƒè©±çµæŸå¾Œåˆªé™¤")
                print(f"   - è«‹å„˜å¿«ä¸‹è¼‰ä»¥ä¸‹æ–‡ä»¶åˆ°æœ¬åœ°ï¼š")

                # åˆ—å‡ºæ‰€æœ‰æ–‡ä»¶ä¸¦æä¾›ä¸‹è¼‰éˆæ¥
                for file in os.listdir(temp_dir):
                    file_path = f"{temp_dir}/{file}"
                    print(f"     - {file}")
                    display(HTML(f'<a href="files/{file_path}" download="{file}">ğŸ“¥ ä¸‹è¼‰ {file}</a>'))

                # æä¾›æ‰“åŒ…ä¸‹è¼‰
                zip_filename = f"{audio_basename}.subtitles.{lang_suffix}.zip"
                zip_path = f"/content/{zip_filename}"
                with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                    for file in os.listdir(temp_dir):
                        file_path = f"{temp_dir}/{file}"
                        zipf.write(file_path, file)

                print(f"\nğŸ“¦ ä¹Ÿå¯ä»¥ä¸‹è¼‰æ‰“åŒ…æ–‡ä»¶ï¼š")
                display(HTML(f'<a href="files/{zip_path}" download="{zip_filename}">ğŸ“¥ ä¸‹è¼‰å…¨éƒ¨æ–‡ä»¶ ({zip_filename})</a>'))

        except Exception as e:
            print(f"\nâŒ è™•ç†éç¨‹å‡ºéŒ¯: {str(e)}")
            import traceback
            traceback.print_exc()

    run_button.on_click(on_run_click)

# ===================== å®‰è£ä¾è³´ =====================
def install_dependencies():
    print("ğŸ“¦ æ­£åœ¨å®‰è£å¿…è¦ä¾è³´...")
    # å®‰è£FFmpeg
    subprocess.run(["apt", "update"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)
    subprocess.run(["apt", "install", "-y", "ffmpeg"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)

    # å®‰è£PythonåŒ… - ä½¿ç”¨ subprocess.run è€Œä¸æ˜¯ !pip
    subprocess.run(["pip", "install", "-q", "ffmpeg-python", "whisperx", "torch", "soundfile", "numpy"])

    print("âœ… ä¾è³´å®‰è£å®Œæˆï¼")

# åŸ·è¡Œå®‰è£å’Œå•“å‹•ç•Œé¢
if __name__ == "__main__":
    install_dependencies()
    main_interface()